{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp, log, sqrt, pi\n",
    "import time\n",
    "import itertools\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler \n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Subset Selection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = os.path.abspath('.')\n",
    "hitters = pd.read_csv(url_path + '\\data\\Hitters.csv', index_col=0)\n",
    "hitters.index.name = 'Player'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Andy Allanson</th>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andres Galarraga</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  \\\n",
       "Player                                                                          \n",
       "-Andy Allanson       293    66      1    30   29     14      1     293     66   \n",
       "-Alan Ashby          315    81      7    24   38     39     14    3449    835   \n",
       "-Alvin Davis         479   130     18    66   72     76      3    1624    457   \n",
       "-Andre Dawson        496   141     20    65   78     37     11    5628   1575   \n",
       "-Andres Galarraga    321    87     10    39   42     30      2     396    101   \n",
       "\n",
       "                   CHmRun  CRuns  CRBI  CWalks League Division  PutOuts  \\\n",
       "Player                                                                    \n",
       "-Andy Allanson          1     30    29      14      A        E      446   \n",
       "-Alan Ashby            69    321   414     375      N        W      632   \n",
       "-Alvin Davis           63    224   266     263      A        W      880   \n",
       "-Andre Dawson         225    828   838     354      N        E      200   \n",
       "-Andres Galarraga      12     48    46      33      N        E      805   \n",
       "\n",
       "                   Assists  Errors  Salary NewLeague  \n",
       "Player                                                \n",
       "-Andy Allanson          33      20     NaN         A  \n",
       "-Alan Ashby             43      10   475.0         N  \n",
       "-Alvin Davis            82      14   480.0         A  \n",
       "-Andre Dawson           11       3   500.0         N  \n",
       "-Andres Galarraga       40       4    91.5         N  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>403.642586</td>\n",
       "      <td>107.828897</td>\n",
       "      <td>11.619772</td>\n",
       "      <td>54.745247</td>\n",
       "      <td>51.486692</td>\n",
       "      <td>41.114068</td>\n",
       "      <td>7.311787</td>\n",
       "      <td>2657.543726</td>\n",
       "      <td>722.186312</td>\n",
       "      <td>69.239544</td>\n",
       "      <td>361.220532</td>\n",
       "      <td>330.418251</td>\n",
       "      <td>260.266160</td>\n",
       "      <td>290.711027</td>\n",
       "      <td>118.760456</td>\n",
       "      <td>8.593156</td>\n",
       "      <td>535.925882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.307209</td>\n",
       "      <td>45.125326</td>\n",
       "      <td>8.757108</td>\n",
       "      <td>25.539816</td>\n",
       "      <td>25.882714</td>\n",
       "      <td>21.718056</td>\n",
       "      <td>4.793616</td>\n",
       "      <td>2286.582929</td>\n",
       "      <td>648.199644</td>\n",
       "      <td>82.197581</td>\n",
       "      <td>331.198571</td>\n",
       "      <td>323.367668</td>\n",
       "      <td>264.055868</td>\n",
       "      <td>279.934575</td>\n",
       "      <td>145.080577</td>\n",
       "      <td>6.606574</td>\n",
       "      <td>451.118681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>282.500000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>842.500000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>413.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>516.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>526.000000</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3890.500000</td>\n",
       "      <td>1054.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>497.500000</td>\n",
       "      <td>424.500000</td>\n",
       "      <td>328.500000</td>\n",
       "      <td>322.500000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>687.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>14053.000000</td>\n",
       "      <td>4256.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>2165.000000</td>\n",
       "      <td>1659.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1377.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AtBat        Hits       HmRun        Runs         RBI       Walks  \\\n",
       "count  263.000000  263.000000  263.000000  263.000000  263.000000  263.000000   \n",
       "mean   403.642586  107.828897   11.619772   54.745247   51.486692   41.114068   \n",
       "std    147.307209   45.125326    8.757108   25.539816   25.882714   21.718056   \n",
       "min     19.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    282.500000   71.500000    5.000000   33.500000   30.000000   23.000000   \n",
       "50%    413.000000  103.000000    9.000000   52.000000   47.000000   37.000000   \n",
       "75%    526.000000  141.500000   18.000000   73.000000   71.000000   57.000000   \n",
       "max    687.000000  238.000000   40.000000  130.000000  121.000000  105.000000   \n",
       "\n",
       "            Years        CAtBat        CHits      CHmRun        CRuns  \\\n",
       "count  263.000000    263.000000   263.000000  263.000000   263.000000   \n",
       "mean     7.311787   2657.543726   722.186312   69.239544   361.220532   \n",
       "std      4.793616   2286.582929   648.199644   82.197581   331.198571   \n",
       "min      1.000000     19.000000     4.000000    0.000000     2.000000   \n",
       "25%      4.000000    842.500000   212.000000   15.000000   105.500000   \n",
       "50%      6.000000   1931.000000   516.000000   40.000000   250.000000   \n",
       "75%     10.000000   3890.500000  1054.000000   92.500000   497.500000   \n",
       "max     24.000000  14053.000000  4256.000000  548.000000  2165.000000   \n",
       "\n",
       "              CRBI       CWalks      PutOuts     Assists      Errors  \\\n",
       "count   263.000000   263.000000   263.000000  263.000000  263.000000   \n",
       "mean    330.418251   260.266160   290.711027  118.760456    8.593156   \n",
       "std     323.367668   264.055868   279.934575  145.080577    6.606574   \n",
       "min       3.000000     1.000000     0.000000    0.000000    0.000000   \n",
       "25%      95.000000    71.000000   113.500000    8.000000    3.000000   \n",
       "50%     230.000000   174.000000   224.000000   45.000000    7.000000   \n",
       "75%     424.500000   328.500000   322.500000  192.000000   13.000000   \n",
       "max    1659.000000  1566.000000  1377.000000  492.000000   32.000000   \n",
       "\n",
       "            Salary  \n",
       "count   263.000000  \n",
       "mean    535.925882  \n",
       "std     451.118681  \n",
       "min      67.500000  \n",
       "25%     190.000000  \n",
       "50%     425.000000  \n",
       "75%     750.000000  \n",
       "max    2460.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_reg(X, y):\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rss =  mse * len(y)\n",
    "    r_squared = model.score(X, y)\n",
    "    return rss, r_squared, mse\n",
    "\n",
    "def calculate_aic(num_obs, mse, num_params):\n",
    "    '''\n",
    "    AIC is derived from a frequentist framework.\n",
    "    AIC cannot be interpreted as an approximation to the marginal likelihood.\n",
    "    AIC penalizes complex models less than BIC.\n",
    "    In general selects more complex models.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    aic = num_obs * log(mse) + 2 * num_params\n",
    "    return aic\n",
    "\n",
    "def calculate_bic(num_obs, mse, num_params):\n",
    "    '''\n",
    "    \n",
    "    Bayesian method.\n",
    "    Models fit under the MLE framework.\n",
    "    If selected candidate models include a true model for the dataset...  \n",
    "    then the probability that BIC will select the true model increases with the size of the training dataset\n",
    "    '''\n",
    "    bic = num_obs * log(mse) + num_params * log(num_obs)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commented out because requires loads of processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ny = hitters['Salary']\\nX = hitters.drop(['League', 'Division', 'Salary', 'NewLeague'], axis=1)\\nrss_arr, r_sqrd_arr, feature_list = [], [], []\\nbic_arr, aic_arr = [], []\\nmse_arr =[]\\nnum_features = []\\n\\nfor feature_idx in trange(1, len(X.columns)+1, desc='Looping...'):\\n    \\n    for permu in itertools.combinations(X.columns, feature_idx):\\n        tmp_rss, tmp_r_sqrd, tmp_mse = fit_linear_reg(X[list(permu)], y)\\n        rss_arr.append(tmp_rss)\\n        r_sqrd_arr.append(tmp_r_sqrd)\\n        mse_arr.append(tmp_mse)\\n        \\n        # information criterion metrics\\n        tmp_aic = calculate_aic(X.shape[0], tmp_mse, len(permu))\\n        aic_arr.append(tmp_aic)\\n        \\n        tmp_bic = calculate_bic(X.shape[0], tmp_mse, len(permu))\\n        bic_arr.append(tmp_bic)\\n        \\n        # record features\\n        feature_list.append(permu)\\n        num_features.append(len(permu))\\n        \\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y = hitters['Salary']\n",
    "X = hitters.drop(['League', 'Division', 'Salary', 'NewLeague'], axis=1)\n",
    "rss_arr, r_sqrd_arr, feature_list = [], [], []\n",
    "bic_arr, aic_arr = [], []\n",
    "mse_arr =[]\n",
    "num_features = []\n",
    "\n",
    "for feature_idx in trange(1, len(X.columns)+1, desc='Looping...'):\n",
    "    \n",
    "    for permu in itertools.combinations(X.columns, feature_idx):\n",
    "        tmp_rss, tmp_r_sqrd, tmp_mse = fit_linear_reg(X[list(permu)], y)\n",
    "        rss_arr.append(tmp_rss)\n",
    "        r_sqrd_arr.append(tmp_r_sqrd)\n",
    "        mse_arr.append(tmp_mse)\n",
    "        \n",
    "        # information criterion metrics\n",
    "        tmp_aic = calculate_aic(X.shape[0], tmp_mse, len(permu))\n",
    "        aic_arr.append(tmp_aic)\n",
    "        \n",
    "        tmp_bic = calculate_bic(X.shape[0], tmp_mse, len(permu))\n",
    "        bic_arr.append(tmp_bic)\n",
    "        \n",
    "        # record features\n",
    "        feature_list.append(permu)\n",
    "        num_features.append(len(permu))\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'num_features': num_features, 'RSS': rss_arr, 'R_Squared': r_sqrd_arr, 'features': feature_list,\n",
    "                  'AIC': aic_arr, 'BIC': bic_arr})\n",
    "df.sort_values('R_Squared', ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(8, 12))\n",
    "sns.scatterplot(x='num_features', y='RSS', data=df, ax=axes[0])\n",
    "sns.scatterplot(x='num_features', y='R_Squared', data=df, ax=axes[1])\n",
    "sns.scatterplot(x='num_features', y='AIC', data=df, ax=axes[2])\n",
    "sns.scatterplot(x='num_features', y='BIC', data=df, ax=axes[3])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(hitters.isnull(), cmap='viridis', cbar=False, yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dependent and categorial variables.\n",
    "X = hitters.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1)\n",
    "y = hitters['Salary']\n",
    "\n",
    "\n",
    "dummies = pd.get_dummies(hitters[['League', 'Division', 'NewLeague']])\n",
    "X = pd.concat([X, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __sklearn Ridge()__ function optimizes:\n",
    "$$ ||X\\beta - y||^2_2 + \\alpha ||\\beta||^2_2 $$\n",
    "which is equivalent to optimizing\n",
    "$$ \\frac{1}{N}||X\\beta - y||^2_2 + \\frac{\\alpha}{N} ||\\beta||^2_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = lambda\n",
    "# lambda is the strength of the regularizatin/shrinkage penalty.\n",
    "# When lambda is 0, the penalty term has no effect. Ridge regression will produce the least squares estimate.\n",
    "# As lambda increases, the impact of the shrinkage penalty grows and the rdige regression coefficients will approach zero.\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "ridge = Ridge()\n",
    "coefs = []\n",
    "\n",
    "# scale() = Center to the mean and component wise scale to unit variance.\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(scale(X), y)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) #reverse axis\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('weights')\n",
    "ax.set_title('Ridge Coefficients as a Function of Regularization')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that as the value of alpha decreases, the Ridge coefficients' values increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unclear as to why JWarmenhoven enter this number\n",
    "# ISLR used alpha = 4.\n",
    "# Maybe b/c the optimization functions differ b/t Sklearn and R.\n",
    "alpha = len(X)*(11498/2)\n",
    "\n",
    "ridge2 = Ridge(alpha=alpha)\n",
    "ridge2.fit(X_train_scaled, y_train)\n",
    "y_pred = ridge2.predict(X_test_scaled)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ridge2.coef_.flatten(), index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "This big penalty shrinks the coefficients to a very large degree and makes the model more biased, resulting in a higher MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10 ** 10\n",
    "ridge2.set_params(alpha=alpha)\n",
    "ridge2.fit(X_train_scaled, y_train)\n",
    "y_pred = ridge2.predict(X_test_scaled)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Identify the optimal value for alpha, i.e., lambda\n",
    "<br><br>\n",
    "By default, RidgeCV performs **Leave-One-Out Cross-Validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas=alphas, scoring='neg_mean_squared_error')\n",
    "ridgecv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2.set_params(alpha=ridgecv.alpha_)\n",
    "ridge2.fit(X_train_scaled, y_train)\n",
    "y_pred = ridge2.predict(X_test_scaled)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ridge2.coef_.flatten(), index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6.2 The Lasso\n",
    "\n",
    "\n",
    "For both __glmnet__ in R and sklearn __Lasso()__ function the standard L1 penalty is:\n",
    "$$ \\lambda |\\beta|_1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=10000)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas*2:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('weights')\n",
    "ax.set_title('Lasso Coefficients as a Function of the Regularization')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above plot shows that depending on the choice of the **tuning parameter** - i.e. alpha - some of the coefficients will be **exactly** equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "lasso_cv.fit(X_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.set_params(alpha=lasso_cv.alpha_)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "print(\"MSE: \", mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the coefficients have been reduced to 0.\n",
    "# Sparse coefficients helps w/ inference\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7.1 Principal Components Regression\n",
    "\n",
    "Scikit-klearn does not have an implementation of PCA and regression combined like the 'pls' package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_reduced = pca.fit_transform(scale(X))\n",
    "\n",
    "print(pca.components_.shape)\n",
    "pd.DataFrame(pca.components_.T).iloc[:4, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_reduced.shape)\n",
    "pd.DataFrame(X_reduced).iloc[:4, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained_arr = np.round(pca.explained_variance_ratio_, decimals=4) * 100\n",
    "cumulative_variance_explained = np.cumsum(variance_explained_arr)\n",
    "num_components = np.arange(0,X_reduced.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(num_components, cumulative_variance_explained)\n",
    "ax.set_title('Cumulative Variance Explained by Number of Components')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-fold CV w/ Shuffle\n",
    "n = len(X_reduced)\n",
    "# shuffle data before splitting it into batches.\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "regr = LinearRegression()\n",
    "mse = []\n",
    "\n",
    "# calculate MSE w/ only intercept. No principal components in the regression.\n",
    "score = -1*cross_val_score(regr, np.ones((n, 1)), y.ravel(), cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "mse.append(score)\n",
    "\n",
    "# Calculate MSE using CV for the 19 principal components.\n",
    "# Add one component at a time.\n",
    "for i in np.arange(1, 20):\n",
    "    score = -1 * cross_val_score(regr, X_reduced[:, :i], y.ravel(), cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(mse, '-v')\n",
    "plt.xlabel('# of Principal Components in Regression')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Salary')\n",
    "plt.xlim(xmin=-1)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all components are included, i.e. number of principal components = 19, it is the same as performing ordinary least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting PCA w/ training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA()\n",
    "X_train_reduced = pca2.fit_transform(X_train_scaled)\n",
    "n = len(X_train_reduced)\n",
    "\n",
    "kf_10 = KFold(n_splits=10, shuffle=False, random_state=1)\n",
    "\n",
    "mse = []\n",
    "\n",
    "# Calculate the MSE w/ only the intercept. No features.\n",
    "score = -1 * cross_val_score(regr, np.ones((n, 1)), y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "mse.append(score)\n",
    "\n",
    "for i in np.arange(1, 20):\n",
    "    score = -1 * cross_val_score(regr, X_train_reduced[:,:i], y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(mse, '-v')\n",
    "plt.xlabel('# of Principal Components in Regression')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Salary')\n",
    "plt.xlim(xmin=-1)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot indicates the lowest training MSE is achieved when performing regression on 6 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform test data with PCA loadings and fit regression on 6 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 6\n",
    "X_test_reduced = pca2.transform(X_test_scaled)[:, :num_components+1]\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train_reduced[:, :num_components+1], y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test_reduced)\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7.2 Partial Least Squares\n",
    "\n",
    "\n",
    "Scikit-learn PLSRegression gives same results as the pls package in R when using 'method='oscorespls'. In the LAB excercise, the standard method is used which is 'kernelpls'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "#10-fold CV w/ shuffle\n",
    "kf_10 = KFold(n_splits=10, shuffle=False, random_state=3)\n",
    "mse = []\n",
    "\n",
    "for i in np.arange(1, 20):\n",
    "    pls = PLSRegression(n_components=i)\n",
    "    score = -1 * cross_val_score(pls, X_train_scaled, y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.arange(1,20), np.array(mse), '-v')\n",
    "plt.xlabel('# of Principal Components in Regression')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Salary')\n",
    "plt.xlim(xmin=-1)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
